<map id="G" name="G">
<area shape="rect" id="node3" href="$Host_8c.html#a0ea9f99f85b380e912940f351366a862" title="Initialize the MPI environment, allowing the CUDA device to be selected before (if necessary)..." alt="" coords="171,5,240,35"/>
<area shape="rect" id="node7" href="$Input_8c.html#a243a9fb9128b70313b30d3f082cc0a61" title="Parses the application&#39;s command&#45;line arguments." alt="" coords="104,59,307,88"/>
<area shape="rect" id="node9" href="$Host_8c.html#aef3118f365ec96030a022fa17b73fc42" title="Generates the 2D topology and establishes the neighbor relationships between MPI processes." alt="" coords="152,112,259,141"/>
<area shape="rect" id="node13" href="$Host_8c.html#a63442a950638ea4accb5dcb5ad7a8b87" title="This allocates and initializes all the relevant data buffers before the Jacobi run." alt="" coords="137,165,273,195"/>
<area shape="rect" id="node15" href="$Host_8c.html#a053b144f9d3b11ad9b3563447876629f" title="This function is called immediately before the main Jacobi loop." alt="" coords="153,219,257,248"/>
<area shape="rect" id="node17" href="$Host_8c.html#a52ea6f92f186de790a55fdf700026dd9" title="This is the main Jacobi loop, which handles device computation and data exchange between MPI processe..." alt="" coords="164,272,247,301"/>
<area shape="rect" id="node36" href="$Host_8c.html#a29316e4a0e49080875975ead1809fdbb" title="This function is called immediately after the main Jacobi loop." alt="" coords="151,325,260,355"/>
<area shape="rect" id="node38" href="$Host_8c.html#ad25cf65f450abbc68de1a6409b0c92ba" title="Close (finalize) the MPI environment and deallocate buffers." alt="" coords="172,379,239,408"/>
<area shape="rect" id="node5" href="$CUDA__Aware__MPI_8c.html#ac7925a5469b04c01679b20577671c975" title="This allows the MPI process to set the CUDA device before the MPI environment is initialized For the ..." alt="" coords="355,5,493,35"/>
<area shape="rect" id="node11" href="$CUDA__Aware__MPI_8c.html#aa8cb031e8cba7840a96582f530283fd5" title="This allows the MPI process to set the CUDA device after the MPI environment is initialized For the C..." alt="" coords="360,112,488,141"/>
<area shape="rect" id="node19" href="$Device_8cu.html#a08324d1c9b1ee7193242670ba4b97d88" title="The host wrapper for one Jacobi iteration." alt="" coords="583,220,703,249"/>
<area shape="rect" id="node23" href="$Device_8cu.html#aeaebe085afbffaa0d6bcd77fa16ceb97" title="The host wrapper for copying the updated block over the old one, after a Jacobi iteration finishes..." alt="" coords="361,272,487,301"/>
<area shape="rect" id="node26" href="$Host_8c.html#ac28696e075d2053b4de5662556c16f3d" title="This performs the exchanging of all necessary halos between 2 neighboring MPI processes." alt="" coords="365,352,483,381"/>
<area shape="rect" id="node21" href="$Device_8cu.html#a87c5ce86d74764a06a13b73dff013870" title="The host function for checking the result of a CUDA API call." alt="" coords="792,299,907,328"/>
<area shape="rect" id="node28" href="$Device_8cu.html#a95a52e3c2e58d2d94403a0dce2e29686" title="The host wrapper for copying (packing) the values on the left and right side of the data block to sep..." alt="" coords="541,324,744,353"/>
<area shape="rect" id="node31" href="$CUDA__Aware__MPI_8c.html#a1dc0674ebcbca5a781885f2204d78251" title="Exchange halo values between 2 direct neighbors This is the main difference between the normal CUDA &amp;..." alt="" coords="585,377,700,407"/>
<area shape="rect" id="node33" href="$Device_8cu.html#a3b641f8b5d521a230416b64d8b809324" title="The host wrapper for copying (unpacking) the values from the halo buffers to the left and right side ..." alt="" coords="564,431,721,460"/>
</map>
